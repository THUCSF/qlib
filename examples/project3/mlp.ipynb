{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../..\")\n",
    "\n",
    "import qlib\n",
    "import pandas as pd\n",
    "from qlib.config import REG_CN\n",
    "from qlib.utils import init_instance_by_config\n",
    "from qlib.workflow import R\n",
    "from qlib.workflow.record_temp import SignalRecord, PortAnaRecord\n",
    "from qlib.utils import flatten_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[24019:MainThread](2021-11-29 21:50:53,685) INFO - qlib.Initialization - [config.py:393] - default_conf: client.\n",
      "[24019:MainThread](2021-11-29 21:50:53,688) WARNING - qlib.Initialization - [config.py:418] - redis connection failed(host=127.0.0.1 port=6379), DiskExpressionCache and DiskDatasetCache will not be used!\n",
      "[24019:MainThread](2021-11-29 21:50:53,691) INFO - qlib.Initialization - [__init__.py:57] - qlib successfully initialized based on client settings.\n",
      "[24019:MainThread](2021-11-29 21:50:53,693) INFO - qlib.Initialization - [__init__.py:59] - data_path={'__DEFAULT_FREQ': PosixPath('/data3/xujianjin/qlib/data/china_stock_qlib_adj')}\n"
     ]
    }
   ],
   "source": [
    "# use default data\n",
    "provider_uri = \"../../data/china_stock_qlib_adj\"  # target_dir\n",
    "qlib.init(provider_uri=provider_uri, region=REG_CN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_sizes = [256, 256, 256, 256]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install necessary libs for CatBoostModel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[24019:MainThread](2021-11-29 21:50:54,729) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:71] - DNN pytorch version...\n",
      "[24019:MainThread](2021-11-29 21:50:54,996) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:88] - DNN parameters setting:\n",
      "layers : [256, 256, 256, 256]\n",
      "lr : 0.001\n",
      "max_steps : 300\n",
      "batch_size : 1024\n",
      "early_stop_rounds : 50\n",
      "eval_steps : 20\n",
      "lr_decay : 0.96\n",
      "lr_decay_steps : 100\n",
      "optimizer : adam\n",
      "loss_type : mse\n",
      "eval_steps : 20\n",
      "seed : None\n",
      "device : cuda:9\n",
      "use_GPU : True\n",
      "weight_decay : 0.0001\n",
      "[24019:MainThread](2021-11-29 21:50:55,006) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:132] - model:\n",
      "Net(\n",
      "  (dnn_layers): ModuleList(\n",
      "    (0): Dropout(p=0.05, inplace=False)\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=40, out_features=256, bias=True)\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (5): Dropout(p=0.05, inplace=False)\n",
      "    (6): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "[24019:MainThread](2021-11-29 21:50:55,008) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:133] - model size: 0.2004 MB\n",
      "[24019:MainThread](2021-11-29 21:51:06,578) INFO - qlib.timer - [log.py:113] - Time cost: 8.301s | Loading data Done\n",
      "[24019:MainThread](2021-11-29 21:51:06,892) INFO - qlib.timer - [log.py:113] - Time cost: 0.241s | DropnaLabel Done\n",
      "/home/xujianjin/data3/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/core/frame.py:3191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "[24019:MainThread](2021-11-29 21:51:14,906) INFO - qlib.timer - [log.py:113] - Time cost: 8.012s | CSZScoreNorm Done\n",
      "[24019:MainThread](2021-11-29 21:51:14,908) INFO - qlib.timer - [log.py:113] - Time cost: 8.328s | fit & process data Done\n",
      "[24019:MainThread](2021-11-29 21:51:14,909) INFO - qlib.timer - [log.py:113] - Time cost: 16.632s | Init data Done\n",
      "[24019:MainThread](2021-11-29 21:51:14,911) INFO - qlib.workflow - [expm.py:282] - No tracking URI is provided. Use the default tracking URI.\n",
      "[24019:MainThread](2021-11-29 21:51:14,914) INFO - qlib.workflow - [expm.py:318] - <mlflow.tracking.client.MlflowClient object at 0x7f5681423fd0>\n",
      "[24019:MainThread](2021-11-29 21:51:14,935) INFO - qlib.workflow - [exp.py:249] - Experiment 1 starts running ...\n",
      "[24019:MainThread](2021-11-29 21:51:15,229) INFO - qlib.workflow - [recorder.py:290] - Recorder 8fd02b66c871427f881ed204602c755a starts running under Experiment 1 ...\n",
      "[24019:MainThread](2021-11-29 21:51:15,596) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:189] - training...\n",
      "[24019:MainThread](2021-11-29 21:51:16,100) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:240] - [Epoch 0]: train_loss nan, valid_loss nan\n",
      "[24019:MainThread](2021-11-29 21:51:16,338) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:240] - [Epoch 20]: train_loss nan, valid_loss nan\n",
      "[24019:MainThread](2021-11-29 21:51:16,609) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:240] - [Epoch 40]: train_loss nan, valid_loss nan\n",
      "[24019:MainThread](2021-11-29 21:51:16,876) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:240] - [Epoch 60]: train_loss nan, valid_loss nan\n",
      "[24019:MainThread](2021-11-29 21:51:17,144) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:240] - [Epoch 80]: train_loss nan, valid_loss nan\n",
      "[24019:MainThread](2021-11-29 21:51:17,395) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:240] - [Epoch 100]: train_loss nan, valid_loss nan\n",
      "[24019:MainThread](2021-11-29 21:51:17,658) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:240] - [Epoch 120]: train_loss nan, valid_loss nan\n",
      "[24019:MainThread](2021-11-29 21:51:17,929) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:240] - [Epoch 140]: train_loss nan, valid_loss nan\n",
      "[24019:MainThread](2021-11-29 21:51:18,200) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:240] - [Epoch 160]: train_loss nan, valid_loss nan\n",
      "[24019:MainThread](2021-11-29 21:51:18,459) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:240] - [Epoch 180]: train_loss nan, valid_loss nan\n",
      "[24019:MainThread](2021-11-29 21:51:18,721) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:240] - [Epoch 200]: train_loss nan, valid_loss nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    11: reducing learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[24019:MainThread](2021-11-29 21:51:18,983) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:240] - [Epoch 220]: train_loss nan, valid_loss nan\n",
      "[24019:MainThread](2021-11-29 21:51:19,247) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:240] - [Epoch 240]: train_loss nan, valid_loss nan\n",
      "[24019:MainThread](2021-11-29 21:51:19,510) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:240] - [Epoch 260]: train_loss nan, valid_loss nan\n",
      "[24019:MainThread](2021-11-29 21:51:19,767) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:240] - [Epoch 280]: train_loss nan, valid_loss nan\n",
      "[24019:MainThread](2021-11-29 21:51:20,018) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:240] - [Epoch 299]: train_loss nan, valid_loss nan\n",
      "[24019:MainThread](2021-11-29 21:51:20,025) INFO - qlib.timer - [log.py:113] - Time cost: 0.000s | waiting `async_log` Done\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d3ca5f71b082>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mflatten_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_recorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/xujianjin/qlib/examples/project3/../../qlib/contrib/model/pytorch_nn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, evals_result, verbose, save_path)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;31m# restore the optimal parameters after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data3/anaconda3/envs/py38/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    593\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data3/anaconda3/envs/py38/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \"functionality.\")\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m     \u001b[0mmagic_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmagic_number\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mMAGIC_NUMBER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid magic number; corrupt file?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "market = \"csi300\"\n",
    "benchmark = \"SH000300\"\n",
    "\n",
    "win_size = 10\n",
    "\n",
    "###################################\n",
    "# train model\n",
    "###################################\n",
    "data_handler_config = {\n",
    "    \"start_time\": \"2008-01-01\",\n",
    "    \"end_time\": \"2020-08-01\",\n",
    "    \"fit_start_time\": \"2008-01-01\",\n",
    "    \"fit_end_time\": \"2014-12-31\",\n",
    "    \"instruments\": market,\n",
    "    \"infer_processors\": [\n",
    "        {\"class\" : \"DropnaProcessor\", \"kwargs\": {\"fields_group\": \"feature\"}},\n",
    "        {\"class\" : \"DropnaProcessor\", \"kwargs\": {\"fields_group\": \"label\"}},\n",
    "    ],\n",
    "    \"learn_processors\": [\n",
    "        {\"class\" : \"DropnaProcessor\", \"kwargs\": {\"fields_group\": \"feature\"}},\n",
    "        {\"class\" : \"DropnaProcessor\", \"kwargs\": {\"fields_group\": \"label\"}},\n",
    "    ],\n",
    "    \"label\": [\"Ref($close, -2) / Ref($close, -1) - 1\"],\n",
    "    \"window\" : win_size,\n",
    "    \"process_type\" : \"independent\"\n",
    "}\n",
    "\n",
    "task = {\n",
    "    \"model\": {\n",
    "        \"class\": \"DNNModelPytorch\",\n",
    "        \"module_path\": \"qlib.contrib.model.pytorch_nn\",\n",
    "        \"kwargs\": {\n",
    "            \"input_dim\" : 4 * win_size,\n",
    "            \"output_dim\" : 1,\n",
    "            \"layers\" : hidden_sizes,\n",
    "            \"lr\" : 0.001,\n",
    "            \"max_steps\" : 300,\n",
    "            \"batch_size\" : 1024,\n",
    "            \"early_stop_rounds\" : 50,\n",
    "            \"eval_steps\" : 20,\n",
    "            \"lr_decay\" : 0.96,\n",
    "            \"lr_decay_steps\" : 100,\n",
    "            \"optimizer\" : \"adam\",\n",
    "            \"loss\" : \"mse\",\n",
    "            \"GPU\" : 9,\n",
    "            \"seed\" : None,\n",
    "            \"weight_decay\" : 1e-4\n",
    "        },\n",
    "    },\n",
    "    \"dataset\": {\n",
    "        \"class\": \"DatasetH\",\n",
    "        \"module_path\": \"qlib.data.dataset\",\n",
    "        \"kwargs\": {\n",
    "            \"handler\": {\n",
    "                \"class\": \"CustomAlpha\",\n",
    "                \"module_path\": \"qlib.contrib.data.handler\",\n",
    "                \"kwargs\": data_handler_config,\n",
    "            },\n",
    "            \"segments\": {\n",
    "                \"train\": (\"2008-01-01\", \"2014-12-31\"),\n",
    "                \"valid\": (\"2015-01-01\", \"2016-12-31\"),\n",
    "                \"test\": (\"2017-01-01\", \"2020-08-01\"),\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# model initiaiton\n",
    "model = init_instance_by_config(task[\"model\"])\n",
    "dataset = init_instance_by_config(task[\"dataset\"])\n",
    "\n",
    "# start exp to train model\n",
    "with R.start(experiment_name=\"train_model\"):\n",
    "    R.log_params(**flatten_dict(task))\n",
    "    model.fit(dataset)\n",
    "    R.save_objects(trained_model=model)\n",
    "    rid = R.get_recorder().id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = dataset.prepare([\"train\", \"valid\"])\n",
    "print(train_df.shape, val_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isna().values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction, backtest & analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###################################\n",
    "# prediction, backtest & analysis\n",
    "###################################\n",
    "port_analysis_config = {\n",
    "    \"executor\": {\n",
    "        \"class\": \"SimulatorExecutor\",\n",
    "        \"module_path\": \"qlib.backtest.executor\",\n",
    "        \"kwargs\": {\n",
    "            \"time_per_step\": \"day\",\n",
    "            \"generate_portfolio_metrics\": True,\n",
    "        },\n",
    "    },\n",
    "    \"strategy\": {\n",
    "        \"class\": \"TopkDropoutStrategy\",\n",
    "        \"module_path\": \"qlib.contrib.strategy.signal_strategy\",\n",
    "        \"kwargs\": {\n",
    "            \"model\": model,\n",
    "            \"dataset\": dataset,\n",
    "            \"topk\": 50,\n",
    "            \"n_drop\": 5,\n",
    "        },\n",
    "    },\n",
    "    \"backtest\": {\n",
    "        \"start_time\": \"2017-01-01\",\n",
    "        \"end_time\": \"2020-08-01\",\n",
    "        \"account\": 100000000,\n",
    "        \"benchmark\": benchmark,\n",
    "        \"exchange_kwargs\": {\n",
    "            \"freq\": \"day\",\n",
    "            \"limit_threshold\": 0.095,\n",
    "            \"deal_price\": \"close\",\n",
    "            \"open_cost\": 0.0005,\n",
    "            \"close_cost\": 0.0015,\n",
    "            \"min_cost\": 5,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# backtest and analysis\n",
    "with R.start(experiment_name=\"backtest_analysis\"):\n",
    "    recorder = R.get_recorder(recorder_id=rid, experiment_name=\"train_model\")\n",
    "    model = recorder.load_object(\"trained_model\")\n",
    "\n",
    "    # prediction\n",
    "    recorder = R.get_recorder()\n",
    "    ba_rid = recorder.id\n",
    "    sr = SignalRecord(model, dataset, recorder)\n",
    "    sr.generate()\n",
    "\n",
    "    # backtest & analysis\n",
    "    par = PortAnaRecord(recorder, port_analysis_config, \"day\")\n",
    "    par.generate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par.portfolio_metric_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyze graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qlib.contrib.report import analysis_model, analysis_position\n",
    "from qlib.data import D\n",
    "recorder = R.get_recorder(recorder_id=ba_rid, experiment_name=\"backtest_analysis\")\n",
    "print(recorder)\n",
    "pred_df = recorder.load_object(\"pred.pkl\")\n",
    "pred_df_dates = pred_df.index.get_level_values(level='datetime')\n",
    "report_normal_df = recorder.load_object(\"portfolio_analysis/report_normal_1day.pkl\")\n",
    "positions = recorder.load_object(\"portfolio_analysis/positions_normal_1day.pkl\")\n",
    "analysis_df = recorder.load_object(\"portfolio_analysis/port_analysis_1day.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysis position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_position.report_graph(report_normal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### risk analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_position.risk_analysis_graph(analysis_df, report_normal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysis model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = dataset.prepare(\"test\", col_set=\"label\")\n",
    "label_df.columns = ['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### score IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = pd.concat([label_df, pred_df], axis=1, sort=True).reindex(label_df.index)\n",
    "analysis_position.score_ic_graph(pred_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'analysis_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-79d143b8fb7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manalysis_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_performance_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'analysis_model' is not defined"
     ]
    }
   ],
   "source": [
    "analysis_model.model_performance_graph(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
