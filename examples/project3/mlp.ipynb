{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../..\")\n",
    "\n",
    "import qlib\n",
    "import pandas as pd\n",
    "from qlib.config import REG_CN\n",
    "from qlib.contrib.model.gbdt import LGBModel\n",
    "from qlib.contrib.data.handler import Alpha158\n",
    "from qlib.contrib.evaluate import (\n",
    "    backtest as normal_backtest,\n",
    "    risk_analysis,\n",
    ")\n",
    "from qlib.utils import exists_qlib_data, init_instance_by_config\n",
    "from qlib.workflow import R\n",
    "from qlib.workflow.record_temp import SignalRecord, PortAnaRecord\n",
    "from qlib.utils import flatten_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18802:MainThread](2021-11-25 17:22:38,039) INFO - qlib.Initialization - [config.py:393] - default_conf: client.\n",
      "[18802:MainThread](2021-11-25 17:22:38,042) WARNING - qlib.Initialization - [config.py:418] - redis connection failed(host=127.0.0.1 port=6379), DiskExpressionCache and DiskDatasetCache will not be used!\n",
      "[18802:MainThread](2021-11-25 17:22:38,045) INFO - qlib.Initialization - [__init__.py:57] - qlib successfully initialized based on client settings.\n",
      "[18802:MainThread](2021-11-25 17:22:38,046) INFO - qlib.Initialization - [__init__.py:59] - data_path={'__DEFAULT_FREQ': PosixPath('/data3/xujianjin/qlib/data/qlib_cn_stock')}\n"
     ]
    }
   ],
   "source": [
    "# use default data\n",
    "provider_uri = \"../../data/qlib_cn_stock\"  # target_dir\n",
    "qlib.init(provider_uri=provider_uri, region=REG_CN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_sizes = [256]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18802:MainThread](2021-11-25 17:22:38,229) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:71] - DNN pytorch version...\n",
      "[18802:MainThread](2021-11-25 17:22:38,231) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:88] - DNN parameters setting:\n",
      "layers : [256]\n",
      "lr : 0.001\n",
      "max_steps : 300\n",
      "batch_size : 1024\n",
      "early_stop_rounds : 50\n",
      "eval_steps : 20\n",
      "lr_decay : 0.96\n",
      "lr_decay_steps : 100\n",
      "optimizer : adam\n",
      "loss_type : mse\n",
      "eval_steps : 20\n",
      "seed : None\n",
      "device : cuda:8\n",
      "use_GPU : True\n",
      "weight_decay : 0.0001\n",
      "[18802:MainThread](2021-11-25 17:22:38,237) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:132] - model:\n",
      "Net(\n",
      "  (dnn_layers): ModuleList(\n",
      "    (0): Dropout(p=0.05, inplace=False)\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=158, out_features=256, bias=True)\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (2): Dropout(p=0.05, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "[18802:MainThread](2021-11-25 17:22:38,238) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:133] - model size: 0.0396 MB\n",
      "[18802:MainThread](2021-11-25 17:23:08,719) INFO - qlib.timer - [log.py:113] - Time cost: 30.457s | Loading data Done\n",
      "[18802:MainThread](2021-11-25 17:23:09,678) INFO - qlib.timer - [log.py:113] - Time cost: 0.725s | DropnaLabel Done\n",
      "/home/xujianjin/data3/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/core/frame.py:3191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "[18802:MainThread](2021-11-25 17:23:17,195) INFO - qlib.timer - [log.py:113] - Time cost: 7.514s | CSZScoreNorm Done\n",
      "[18802:MainThread](2021-11-25 17:23:17,198) INFO - qlib.timer - [log.py:113] - Time cost: 8.477s | fit & process data Done\n",
      "[18802:MainThread](2021-11-25 17:23:17,199) INFO - qlib.timer - [log.py:113] - Time cost: 38.937s | Init data Done\n",
      "[18802:MainThread](2021-11-25 17:23:17,200) INFO - qlib.workflow - [expm.py:282] - No tracking URI is provided. Use the default tracking URI.\n",
      "[18802:MainThread](2021-11-25 17:23:17,201) INFO - qlib.workflow - [expm.py:318] - <mlflow.tracking.client.MlflowClient object at 0x7f2ad94214c0>\n",
      "[18802:MainThread](2021-11-25 17:23:17,205) INFO - qlib.workflow - [exp.py:249] - Experiment 1 starts running ...\n",
      "[18802:MainThread](2021-11-25 17:23:17,214) INFO - qlib.workflow - [recorder.py:290] - Recorder dce5e2584aab4c759a7727e28a1b5718 starts running under Experiment 1 ...\n",
      "[18802:MainThread](2021-11-25 17:23:17,971) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:189] - training...\n",
      "[18802:MainThread](2021-11-25 17:23:18,024) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:241] - [Epoch 0]: train_loss nan, valid_loss nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.4985, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.5046, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.8334, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.8776, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.5743, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.8227, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.6441, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.1269, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.6886, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(7.1877, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.0600, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(3.9984, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(7.9284, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(3.8401, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.3500, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.7035, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.4874, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.9873, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.6141, device='cuda:8')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18802:MainThread](2021-11-25 17:23:18,234) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:241] - [Epoch 20]: train_loss nan, valid_loss nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.3265, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.2272, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.7700, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.9678, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.5331, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.0868, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.7541, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.6582, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.2715, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.0767, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.5149, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(7.9142, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.0996, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.6867, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.2111, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.2246, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.4494, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.7023, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.5791, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.2148, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.1947, device='cuda:8')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18802:MainThread](2021-11-25 17:23:18,431) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:241] - [Epoch 40]: train_loss nan, valid_loss nan\n",
      "[18802:MainThread](2021-11-25 17:23:18,599) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:241] - [Epoch 60]: train_loss nan, valid_loss nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.8801, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.4095, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.4384, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.7706, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.5331, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(7.2748, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.7028, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.4245, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.2300, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.4808, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.2274, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.9690, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.6890, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.3002, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.4275, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.8220, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.1539, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.5180, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.2114, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.2765, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.1384, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.3259, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.3850, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18802:MainThread](2021-11-25 17:23:18,770) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:241] - [Epoch 80]: train_loss nan, valid_loss nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.8365, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.8621, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.6852, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.7103, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.3556, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(7.8055, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.3927, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.4493, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.2182, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.3246, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.6529, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.2909, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.0663, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.0868, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.6396, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(7.4172, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.3688, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.1668, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.7314, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.5278, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.4193, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.1555, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.0912, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.0319, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18802:MainThread](2021-11-25 17:23:18,929) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:241] - [Epoch 100]: train_loss nan, valid_loss nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.6076, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(7.3809, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.9293, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.0263, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.0758, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.4508, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.2234, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.4959, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.1263, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.0507, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.3500, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.3676, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.8073, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.5922, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.9690, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.1760, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.9817, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.6272, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.2274, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.4091, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.1774, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.2318, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.5136, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(9.9425, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.2875, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.1389, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.7654, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.6782, device='cuda:8')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18802:MainThread](2021-11-25 17:23:19,070) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:241] - [Epoch 120]: train_loss nan, valid_loss nan\n",
      "[18802:MainThread](2021-11-25 17:23:19,215) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:241] - [Epoch 140]: train_loss nan, valid_loss nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(7.4172, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.7783, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.1120, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(7.0160, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.8007, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.7339, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.0912, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.3643, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.6993, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.5972, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.4460, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(9.7723, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.7271, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.7699, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(7.2381, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.8895, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.9392, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.2365, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.7443, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.3565, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.9318, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.1658, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.7157, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.3070, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(7.1852, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.2814, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.1314, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18802:MainThread](2021-11-25 17:23:19,373) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:241] - [Epoch 160]: train_loss nan, valid_loss nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.9575, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.6672, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.0767, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(7.2022, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.1901, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.6367, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.2028, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.7442, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.4328, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.1901, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.4459, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.5910, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.8123, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.3180, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.5379, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.7086, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.6841, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.5382, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(7.1852, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.3275, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.5136, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.5468, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.2479, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.2272, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.8914, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.9865, device='cuda:8')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18802:MainThread](2021-11-25 17:23:19,546) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:241] - [Epoch 180]: train_loss nan, valid_loss nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.5743, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.9394, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.2324, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.3111, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.4831, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.4897, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.8503, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.1630, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.2062, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.4494, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.0155, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.5267, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.3446, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.9658, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.2496, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.7572, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.1559, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.4106, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.4459, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.7515, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.1639, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.4189, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.8598, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.2715, device='cuda:8')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18802:MainThread](2021-11-25 17:23:19,705) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:241] - [Epoch 200]: train_loss nan, valid_loss nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.0120, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.7185, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.2551, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(7.2420, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(7.2420, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(7.2532, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.4932, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.1438, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.8621, device='cuda:8')\n",
      "Epoch    11: reducing learning rate of group 0 to 5.0000e-04.\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.7548, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(7.0459, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.5201, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.2131, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.8008, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.9004, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.6597, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.5963, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.8598, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.8497, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.4502, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.8621, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.1120, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.3688, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.0739, device='cuda:8')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18802:MainThread](2021-11-25 17:23:19,884) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:241] - [Epoch 220]: train_loss nan, valid_loss nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.8505, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.0985, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.4874, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(3.7362, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(7.4177, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.6597, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.3880, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.8175, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.0613, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.2264, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.0903, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.3676, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.3115, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(8.1053, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.8348, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.6867, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(9.9425, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.4354, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.5910, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.0669, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(7.1877, device='cuda:8')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18802:MainThread](2021-11-25 17:23:20,087) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:241] - [Epoch 240]: train_loss nan, valid_loss nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.7485, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.4785, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.4193, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.6141, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.8326, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.8749, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.9170, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.4950, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.9678, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.1015, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.5456, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.3848, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(7.2748, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.8334, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.8823, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.1391, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.9873, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.9462, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.3315, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.2527, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.1774, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.0968, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.3777, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.5567, device='cuda:8')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18802:MainThread](2021-11-25 17:23:20,251) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:241] - [Epoch 260]: train_loss nan, valid_loss nan\n",
      "[18802:MainThread](2021-11-25 17:23:20,430) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:241] - [Epoch 280]: train_loss nan, valid_loss nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.3430, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.7592, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.4959, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.3831, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.9628, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.4932, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.7813, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(7.2109, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.8914, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.9392, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.7700, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(7.2022, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.4417, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.1760, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.2270, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.1833, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.6597, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.0303, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.6202, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.0903, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.8941, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.0868, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.0396, device='cuda:8')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18802:MainThread](2021-11-25 17:23:20,610) INFO - qlib.DNNModelPytorch - [pytorch_nn.py:241] - [Epoch 299]: train_loss nan, valid_loss nan\n",
      "[18802:MainThread](2021-11-25 17:23:20,618) INFO - qlib.timer - [log.py:113] - Time cost: 0.002s | waiting `async_log` Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.4078, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.9873, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.9397, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.6559, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.1848, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.6141, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.0405, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.5136, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(7.2381, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.4455, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.2120, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.3151, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.7460, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(5.7290, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(6.6559, device='cuda:8')\n",
      "torch.Size([1024, 158]) torch.Size([1024, 1]) torch.Size([1024, 1]) tensor(nan, device='cuda:8') tensor(nan, device='cuda:8', grad_fn=<MaxBackward1>) tensor(4.6443, device='cuda:8')\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ea1c6e5e22b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mflatten_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_recorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data3/xujianjin/qlib/examples/project3/../../qlib/contrib/model/pytorch_nn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, evals_result, verbose, save_path)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# restore the optimal parameters after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data3/anaconda3/envs/py38/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    593\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data3/anaconda3/envs/py38/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \"functionality.\")\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m     \u001b[0mmagic_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmagic_number\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mMAGIC_NUMBER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid magic number; corrupt file?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "market = \"csi300\"\n",
    "benchmark = \"SH000300\"\n",
    "\n",
    "###################################\n",
    "# train model\n",
    "###################################\n",
    "data_handler_config = {\n",
    "    \"start_time\": \"2008-01-01\",\n",
    "    \"end_time\": \"2020-08-01\",\n",
    "    \"fit_start_time\": \"2008-01-01\",\n",
    "    \"fit_end_time\": \"2014-12-31\",\n",
    "    \"instruments\": market,\n",
    "}\n",
    "\n",
    "task = {\n",
    "    \"model\": {\n",
    "        \"class\": \"DNNModelPytorch\",\n",
    "        \"module_path\": \"qlib.contrib.model.pytorch_nn\",\n",
    "        \"kwargs\": {\n",
    "            \"input_dim\" : 158,\n",
    "            \"output_dim\" : 1,\n",
    "            \"layers\" : hidden_sizes,\n",
    "            \"lr\" : 0.001,\n",
    "            \"max_steps\" : 300,\n",
    "            \"batch_size\" : 1024,\n",
    "            \"early_stop_rounds\" : 50,\n",
    "            \"eval_steps\" : 20,\n",
    "            \"lr_decay\" : 0.96,\n",
    "            \"lr_decay_steps\" : 100,\n",
    "            \"optimizer\" : \"adam\",\n",
    "            \"loss\" : \"mse\",\n",
    "            \"GPU\" : 8,\n",
    "            \"seed\" : None,\n",
    "            \"weight_decay\" : 1e-4\n",
    "        },\n",
    "    },\n",
    "    \"dataset\": {\n",
    "        \"class\": \"DatasetH\",\n",
    "        \"module_path\": \"qlib.data.dataset\",\n",
    "        \"kwargs\": {\n",
    "            \"handler\": {\n",
    "                \"class\": \"Alpha158\",\n",
    "                \"module_path\": \"qlib.contrib.data.handler\",\n",
    "                \"kwargs\": data_handler_config,\n",
    "            },\n",
    "            \"segments\": {\n",
    "                \"train\": (\"2008-01-01\", \"2014-12-31\"),\n",
    "                \"valid\": (\"2015-01-01\", \"2016-12-31\"),\n",
    "                \"test\": (\"2017-01-01\", \"2020-08-01\"),\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# model initiaiton\n",
    "model = init_instance_by_config(task[\"model\"])\n",
    "dataset = init_instance_by_config(task[\"dataset\"])\n",
    "\n",
    "# start exp to train model\n",
    "with R.start(experiment_name=\"train_model\"):\n",
    "    R.log_params(**flatten_dict(task))\n",
    "    model.fit(dataset)\n",
    "    R.save_objects(trained_model=model)\n",
    "    rid = R.get_recorder().id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction, backtest & analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###################################\n",
    "# prediction, backtest & analysis\n",
    "###################################\n",
    "port_analysis_config = {\n",
    "    \"executor\": {\n",
    "        \"class\": \"SimulatorExecutor\",\n",
    "        \"module_path\": \"qlib.backtest.executor\",\n",
    "        \"kwargs\": {\n",
    "            \"time_per_step\": \"day\",\n",
    "            \"generate_portfolio_metrics\": True,\n",
    "        },\n",
    "    },\n",
    "    \"strategy\": {\n",
    "        \"class\": \"TopkDropoutStrategy\",\n",
    "        \"module_path\": \"qlib.contrib.strategy.signal_strategy\",\n",
    "        \"kwargs\": {\n",
    "            \"model\": model,\n",
    "            \"dataset\": dataset,\n",
    "            \"topk\": 50,\n",
    "            \"n_drop\": 5,\n",
    "        },\n",
    "    },\n",
    "    \"backtest\": {\n",
    "        \"start_time\": \"2017-01-01\",\n",
    "        \"end_time\": \"2020-08-01\",\n",
    "        \"account\": 100000000,\n",
    "        \"benchmark\": benchmark,\n",
    "        \"exchange_kwargs\": {\n",
    "            \"freq\": \"day\",\n",
    "            \"limit_threshold\": 0.095,\n",
    "            \"deal_price\": \"close\",\n",
    "            \"open_cost\": 0.0005,\n",
    "            \"close_cost\": 0.0015,\n",
    "            \"min_cost\": 5,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# backtest and analysis\n",
    "with R.start(experiment_name=\"backtest_analysis\"):\n",
    "    recorder = R.get_recorder(recorder_id=rid, experiment_name=\"train_model\")\n",
    "    model = recorder.load_object(\"trained_model\")\n",
    "\n",
    "    # prediction\n",
    "    recorder = R.get_recorder()\n",
    "    ba_rid = recorder.id\n",
    "    sr = SignalRecord(model, dataset, recorder)\n",
    "    sr.generate()\n",
    "\n",
    "    # backtest & analysis\n",
    "    par = PortAnaRecord(recorder, port_analysis_config, \"day\")\n",
    "    par.generate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyze graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qlib.contrib.report import analysis_model, analysis_position\n",
    "from qlib.data import D\n",
    "recorder = R.get_recorder(recorder_id=ba_rid, experiment_name=\"backtest_analysis\")\n",
    "print(recorder)\n",
    "pred_df = recorder.load_object(\"pred.pkl\")\n",
    "pred_df_dates = pred_df.index.get_level_values(level='datetime')\n",
    "report_normal_df = recorder.load_object(\"portfolio_analysis/report_normal_1day.pkl\")\n",
    "positions = recorder.load_object(\"portfolio_analysis/positions_normal_1day.pkl\")\n",
    "analysis_df = recorder.load_object(\"portfolio_analysis/port_analysis_1day.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysis position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_position.report_graph(report_normal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### risk analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_position.risk_analysis_graph(analysis_df, report_normal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysis model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = dataset.prepare(\"test\", col_set=\"label\")\n",
    "label_df.columns = ['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### score IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = pd.concat([label_df, pred_df], axis=1, sort=True).reindex(label_df.index)\n",
    "analysis_position.score_ic_graph(pred_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_model.model_performance_graph(pred_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
